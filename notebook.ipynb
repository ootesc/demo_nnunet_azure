{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "from azureml.core import Workspace\n",
        "from azure.ai import ml\n",
        "from azure.ai.ml import entities"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1729589538323
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the workspace configuration\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Optionally, you can print the workspace details to confirm\n",
        "print(ws.name, ws.resource_group, ws.location)\n",
        "\n",
        "# Initialize MLClient\n",
        "ml_client = ml.MLClient(\n",
        "    DefaultAzureCredential(),\n",
        "    subscription_id=ws.subscription_id,\n",
        "    resource_group_name=ws.resource_group,\n",
        "    workspace_name=ws.name\n",
        ")\n",
        "\n",
        "# Print workspace details to confirm\n",
        "print(f\"Connected to workspace: {ml_client.workspace_name}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "amlstudiochristest c.l.m.ootes-rg westeurope\nConnected to workspace: amlstudiochristest\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1729589562642
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting the correct number of Workers for data augmentation (training only)\n",
        "Note that you will need to manually set the number of processes nnU-Net uses for data augmentation according to your CPU/GPU ratio. For the server above (256 threads for 8 GPUs), a good value would be 24-30. You can do this by setting the nnUNet_n_proc_DA environment variable (export nnUNet_n_proc_DA=XX). Recommended values (assuming a recent CPU with good IPC) are 10-12 for RTX 2080 ti, 12 for a RTX 3090, 16-18 for RTX 4090, 28-32 for A100. Optimal values may vary depending on the number of input channels/modalities and number of classes."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1729589739848
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}